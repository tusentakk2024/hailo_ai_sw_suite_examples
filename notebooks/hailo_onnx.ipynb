{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a5fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from hailo_sdk_client import ClientRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7bac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_hw_arch = \"hailo8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c16da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://onnx.ai/models/\n",
    "onnx_model_name = \"resnet10t_Opset16\"\n",
    "onnx_path = \"resnet10t_Opset16.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbce160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Translation started on ONNX model resnet10t_Opset16\n",
      "[info] Restored ONNX model resnet10t_Opset16 (completion time: 00:00:00.07)\n",
      "[info] Extracted ONNXRuntime meta-data for Hailo model (completion time: 00:00:00.20)\n",
      "[info] Start nodes mapped from original model: 'x': 'resnet10t_Opset16/input_layer1'.\n",
      "[info] End nodes mapped from original model: '/fc/Gemm'.\n",
      "[info] Translation completed on ONNX model resnet10t_Opset16 (completion time: 00:00:00.55)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 16:13:01.050195: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 16:13:01.070757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 16:13:01.070793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 16:13:01.073277: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 16:13:01.073311: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 16:13:01.073327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 16:13:01.161637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 16:13:01.161683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 16:13:01.161687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-02-11 16:13:01.161705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-11 16:13:01.161713: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-02-11 16:13:01.161729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5529 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-02-11 16:13:01.189962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8906\n"
     ]
    }
   ],
   "source": [
    "runner = ClientRunner(hw_arch=chosen_hw_arch)\n",
    "hn, npz = runner.translate_onnx_model(\n",
    "    onnx_path,\n",
    "    onnx_model_name,\n",
    "    start_node_names=[\"x\"],\n",
    "    end_node_names=[\"136\"],\n",
    "    net_input_shapes={\"x\": [1, 3, 176, 176]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26e801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Saved HAR to: /local/workspace/share/hailo/resnet10t_Opset16_hailo_model.har\n"
     ]
    }
   ],
   "source": [
    "hailo_model_har_name = f\"{onnx_model_name}_hailo_model.har\"\n",
    "runner.save_har(hailo_model_har_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd46817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy dataset\n",
    "calib_dataset = np.random.randint(0, 255, (1024, 176, 176, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a4acc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Starting Model Optimization\n",
      "[info] Using default optimization level of 2\n",
      "[info] Model received quantization params from the hn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 16:44:40.022859: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "2025-02-11 16:44:40.097547: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] MatmulDecompose skipped\n",
      "[info] Starting Mixed Precision\n",
      "[info] Model Optimization Algorithm Mixed Precision is done (completion time is 00:00:00.11)\n",
      "[info] LayerNorm Decomposition skipped\n",
      "[info] Starting Statistics Collector\n",
      "[info] Using dataset with 64 entries for calibration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration:   0%|                                                                          | 0/64 [00:00<?, ?entries/s]2025-02-11 16:44:43.099374: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-02-11 16:44:43.131919: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,176,176,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-02-11 16:44:47.972557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Calibration:  12%|████████▎                                                         | 8/64 [00:05<00:40,  1.37entries/s]2025-02-11 16:44:48.173811: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,176,176,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-02-11 16:44:48.197760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,176,176,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-02-11 16:44:48.218924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,176,176,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-02-11 16:44:48.242688: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,176,176,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-02-11 16:44:48.269064: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,176,176,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Calibration:  75%|████████████████████████████████████████████████▊                | 48/64 [00:05<00:01, 10.85entries/s]2025-02-11 16:44:48.290457: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,176,176,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-02-11 16:44:48.310436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,176,176,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Calibration: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:05<00:00, 10.67entries/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Model Optimization Algorithm Statistics Collector is done (completion time is 00:00:06.47)\n",
      "[info] Starting Fix zp_comp Encoding\n",
      "[info] Model Optimization Algorithm Fix zp_comp Encoding is done (completion time is 00:00:00.00)\n",
      "[info] Matmul Equalization skipped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 16:44:52.505009: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Finetune encoding skipped\n",
      "[info] Bias Correction skipped\n",
      "[info] Adaround skipped\n",
      "[info] Starting Quantization-Aware Fine-Tuning\n",
      "[info] Using dataset with 1024 entries for finetune\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 16:44:54.118156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-02-11 16:44:54.118355: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-02-11 16:45:05.576878: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inSelectV2_6-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-02-11 16:45:07.174798: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fb768424a20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-02-11 16:45:07.174831: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Ti, Compute Capability 8.9\n",
      "2025-02-11 16:45:07.181600: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-02-11 16:45:07.274494: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 19s 44ms/step - total_distill_loss: 0.0359 - _distill_loss_resnet10t_Opset16/fc1: 0.0359\n",
      "Epoch 2/4\n",
      "128/128 [==============================] - 6s 44ms/step - total_distill_loss: 0.0482 - _distill_loss_resnet10t_Opset16/fc1: 0.0482\n",
      "Epoch 3/4\n",
      "128/128 [==============================] - 6s 44ms/step - total_distill_loss: 0.0363 - _distill_loss_resnet10t_Opset16/fc1: 0.0363\n",
      "Epoch 4/4\n",
      "128/128 [==============================] - 6s 45ms/step - total_distill_loss: 0.0257 - _distill_loss_resnet10t_Opset16/fc1: 0.0257\n",
      "[info] Model Optimization Algorithm Quantization-Aware Fine-Tuning is done (completion time is 00:00:37.34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 16:45:32.385783: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1279] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Starting Layer Noise Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full Quant Analysis:   0%|                                                                | 0/2 [00:00<?, ?iterations/s]2025-02-11 16:45:33.191549: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Full Quant Analysis:  50%|████████████████████████████                            | 1/2 [00:00<00:00,  4.21iterations/s]2025-02-11 16:45:33.217399: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,176,176,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Full Quant Analysis: 100%|████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  8.62s/iterations]2025-02-11 16:45:47.711863: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [8,176,176,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "Full Quant Analysis: 100%|████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.44s/iterations]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Model Optimization Algorithm Layer Noise Analysis is done (completion time is 00:00:15.86)\n",
      "[info] Output layers signal-to-noise ratio (SNR): measures the quantization noise (higher is better)\n",
      "[info] \tresnet10t_Opset16/output_layer1 SNR:\t34.49 dB\n",
      "[info] The calibration set indicates that the neural core receives values of range [(0.0, 254.0), (0.0, 254.0), (0.0, 254.0)].\n",
      "Consider forcing the range (using the quantization_param(resnet10t_Opset16/input_layer1, force_range_out=[0, 255]) model script command) to be exactly [0, 255] to save CPU utilization on runtime.\n",
      "Refer to the user guide tutorial Hailo Dataflow Compiler user guide / Model Optimization / Optimization Related Model Script Commands / quantization_param / force_range_out for details.\n",
      "[info] Model Optimization is done\n"
     ]
    }
   ],
   "source": [
    "runner.optimize(calib_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76becdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Saved HAR to: /local/workspace/share/hailo/resnet10t_Opset16_quantized_model.har\n"
     ]
    }
   ],
   "source": [
    "quantized_model_har_path = f\"{onnx_model_name}_quantized_model.har\"\n",
    "runner.save_har(quantized_model_har_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "542707b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] To achieve optimal performance, set the compiler_optimization_level to \"max\" by adding performance_param(compiler_optimization_level=max) to the model script. Note that this may increase compilation time.\n",
      "[info] Loading network parameters\n",
      "[info] Starting Hailo allocation and compilation flow\n",
      "[info] Using Single-context flow\n",
      "[info] Resources optimization guidelines: Strategy -> GREEDY Objective -> MAX_FPS\n",
      "[info] Resources optimization params: max_control_utilization=75%, max_compute_utilization=75%, max_compute_16bit_utilization=75%, max_memory_utilization (weights)=75%, max_input_aligner_utilization=75%, max_apu_utilization=75%\n",
      "[info] Using Single-context flow\n",
      "[info] Resources optimization guidelines: Strategy -> GREEDY Objective -> MAX_FPS\n",
      "[info] Resources optimization params: max_control_utilization=75%, max_compute_utilization=75%, max_compute_16bit_utilization=75%, max_memory_utilization (weights)=75%, max_input_aligner_utilization=75%, max_apu_utilization=75%\n",
      "[info] input_layer1: Pass\n",
      "[info] output_layer1: Pass\n",
      "[info] conv1_sd0: Pass\n",
      "[info] conv2_sdc: Pass\n",
      "[info] const_input1: Pass\n",
      "[info] sh_from_smuffers_shortcut_conv2_to_conv3_to_conv3_sd0-3: Pass\n",
      "[info] smuffers_shortcut_conv2_to_conv3: Pass\n",
      "[info] conv2_sd0: Pass\n",
      "[info] sh_from_smuffers_shortcut_conv2_to_conv3_to_conv3_sd4-7: Pass\n",
      "[info] conv1_sd1: Pass\n",
      "[info] concat_from_conv3_sd0-3_to_conv3_sdc: Pass\n",
      "[info] conv3_sd5: Pass\n",
      "[info] conv3_sd2: Pass\n",
      "[info] conv1_sdc: Pass\n",
      "[info] conv3_sd3: Pass\n",
      "[info] conv2_sd2: Pass\n",
      "[info] conv3_sd1: Pass\n",
      "[info] conv3_sd7: Pass\n",
      "[info] conv3_sd4: Pass\n",
      "[info] conv3_sd0: Pass\n",
      "[info] concat_from_conv3_sd4-7_to_conv3_sdc: Pass\n",
      "[info] conv2_sd1: Pass\n",
      "[info] conv3_sd6: Pass\n",
      "[info] maxpool1_d4: Pass\n",
      "[info] conv3_sdc: Pass\n",
      "[info] maxpool1_d2: Pass\n",
      "[info] maxpool1_fs: Pass\n",
      "[info] maxpool1_d0: Pass\n",
      "[info] maxpool1_d5: Pass\n",
      "[info] maxpool1_dc: Pass\n",
      "[info] concat_from_maxpool1_d0-3_to_maxpool1_dc: Pass\n",
      "[info] fs_from_maxpool1_fs_to_maxpool1_d0-3: Pass\n",
      "[info] maxpool1_d1: Pass\n",
      "[info] conv4_sdc: Pass\n",
      "[info] maxpool1_d3: Pass\n",
      "[info] avgpool1: Pass\n",
      "[info] conv5_sdc: Pass\n",
      "[info] conv4_sd0: Pass\n",
      "[info] conv6_sd0: Pass\n",
      "[info] conv8_sdc: Pass\n",
      "[info] conv6_sdc: Pass\n",
      "[info] avgpool2: Pass\n",
      "[info] conv5_sd0: Pass\n",
      "[info] conv6_sd1: Pass\n",
      "[info] conv4_sd1: Pass\n",
      "[info] conv4_sd2: Pass\n",
      "[info] conv7: Pass\n",
      "[info] conv10_sdc: Pass\n",
      "[info] conv5_sd1: Pass\n",
      "[info] conv5_sd2: Pass\n",
      "[info] conv8_sd1: Pass\n",
      "[info] conv10_sd1: Pass\n",
      "[info] conv8_sd0: Pass\n",
      "[info] conv10_sd0: Pass\n",
      "[info] conv11_d0: Pass\n",
      "[info] auto_reshape_from_input_layer1_to_conv1_sd0-1: Pass\n",
      "[info] concat_from_conv11_d0-2_to_conv11_dc: Pass\n",
      "[info] conv8_sd2: Pass\n",
      "[info] conv11_dc: Pass\n",
      "[info] conv11_d1: Pass\n",
      "[info] conv9: Pass\n",
      "[info] conv12_dc: Pass\n",
      "[info] conv13: Pass\n",
      "[info] conv14_dc: Pass\n",
      "[info] ew_mult1: Pass\n",
      "[info] concat_from_conv14_d0-2_to_conv14_dc: Pass\n",
      "[info] conv14_d0: Pass\n",
      "[info] conv11_d3: Pass\n",
      "[info] fc1: Pass\n",
      "[info] external_pad1: Pass\n",
      "[info] conv14_d2: Pass\n",
      "[info] conv11_d2: Pass\n",
      "[info] avgpool3: Pass\n",
      "[info] conv12_d1: Pass\n",
      "[info] avgpool4: Pass\n",
      "[info] conv12_d0: Pass\n",
      "[info] conv14_d3: Pass\n",
      "[info] sh_from_maxpool1_dc_to_conv4_sd0-2_conv5_sd0: Pass\n",
      "[info] conv14_d1: Pass\n",
      "[info] Solving the allocation (Mapping), time per context: 59m 59s\n",
      "\n",
      "\n",
      "[info] Context:0/0 Iteration 0: Mapping prepost...          \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1                                                                                                  \n",
      " worker2                                                                                                  \n",
      " worker3                                                                                                  \n",
      "\n",
      "  00:00\n",
      "[info] Context:0/0 Iteration 0: Trying parallel splits...   \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0                                                                                                  \n",
      " worker1                                                                                                  \n",
      " worker2                                                                                                  \n",
      " worker3                                                                                                  \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 0: Trying parallel splits...   \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0                                                                                                  \n",
      " worker1                                                                                                  \n",
      " worker2  *          *          *          *          *          *          *          *          V       \n",
      " worker3                                                                                                  \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 0: Trying parallel splits...   \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0                                                                                                  \n",
      " worker1  *          *          *          *          *          *          *          *          V       \n",
      " worker2  *          *          *          *          *          *          *          *          V       \n",
      " worker3                                                                                                  \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 0: Trying parallel splits...   \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0                                                                                                  \n",
      " worker1  *          *          *          *          *          *          *          *          V       \n",
      " worker2  *          *          *          *          *          *          *          *          V       \n",
      " worker3  *          *          *          *          *          *          *          *          V       \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          *          *          *          *          *          *          *          V       \n",
      " worker2  *          *          *          *          *          *          *          *          V       \n",
      " worker3  *          *          *          *          *          *          *          *          V       \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          *          *          *          *          *          *          *          V       \n",
      " worker2  *          *          *          *          *          *          *          *          V       \n",
      " worker3  *          *          *          *          *          *          *          *          V       \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          *          *          *          *          *          *          *          V       \n",
      " worker2  *          *          *          V          *          *          *          *          V       \n",
      " worker3  *          *          *          *          *          *          *          *          V       \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          *          *          *          *          *          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  *          *          *          *          *          *          *          *          V       \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          *          *          *          *          *          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  *          *          *          *          *          *          *          *          V       \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          *          *          *          *          *          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  *          *          *          *          *          *          *          *          V       \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          *          *          V          *          *          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  *          *          *          *          *          *          *          *          V       \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          *          V          *          *          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  *          *          *          *          *          *          *          *          V       \n",
      "\n",
      "  00:02\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          *          V          *          *          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  *          *          *          *          *          *          *          *          V       \n",
      "\n",
      "  00:03\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          V          V          *          V          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  *          *          *          *          *          *          *          *          V       \n",
      "\n",
      "  00:03\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          V          V          *          V          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  V          V          *          *          *          *          *          V          V       \n",
      "\n",
      "  00:03\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          V          V          *          V          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  V          V          *          *          *          *          *          V          V       \n",
      "\n",
      "  00:03\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          V          V          *          V          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  V          V          *          *          *          V          *          V          V       \n",
      "\n",
      "  00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          V          V          *          V          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  V          V          *          *          *          V          *          V          V       \n",
      "\n",
      "  00:03\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          V          V          *          V          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  V          V          *          *          *          V          *          V          V       \n",
      "\n",
      "  00:03\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          V          V          *          V          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  V          V          *          *          *          V          *          V          V       \n",
      "\n",
      "  00:03\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          V          V          *          V          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  V          V          *          *          *          V          *          V          V       \n",
      "\n",
      "  00:03\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          V          V          *          V          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  V          V          V          *          *          V          *          V          V       \n",
      "\n",
      "  00:03\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  *          V          V          V          *          V          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  V          V          V          V          *          V          *          V          V       \n",
      "\n",
      "  00:03\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  V          V          V          V          *          V          *          *          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  V          V          V          V          *          V          *          V          V       \n",
      "\n",
      "  00:03\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  V          V          V          V          *          V          *          V          V       \n",
      " worker2  *          V          *          V          *          *          V          *          V       \n",
      " worker3  V          V          V          V          *          V          *          V          V       \n",
      "\n",
      "  00:04\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  V          V          V          V          *          V          *          V          V       \n",
      " worker2  V          V          *          V          *          V          V          *          V       \n",
      " worker3  V          V          V          V          *          V          *          V          V       \n",
      "\n",
      "  00:04\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  V          V          V          V          *          V          *          V          V       \n",
      " worker2  V          V          V          V          *          V          V          *          V       \n",
      " worker3  V          V          V          V          *          V          *          V          V       \n",
      "\n",
      "  00:04\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  V          V          V          V          *          V          *          V          V       \n",
      " worker2  V          V          V          V          *          V          V          *          V       \n",
      " worker3  V          V          V          V          *          V          V          V          V       \n",
      "\n",
      "  00:04\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  V          V          V          V          V          V          *          V          V       \n",
      " worker2  V          V          V          V          *          V          V          *          V       \n",
      " worker3  V          V          V          V          *          V          V          V          V       \n",
      "\n",
      "  00:04\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  V          V          V          V          V          V          *          V          V       \n",
      " worker2  V          V          V          V          *          V          V          *          V       \n",
      " worker3  V          V          V          V          V          V          V          V          V       \n",
      "\n",
      "  00:05\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  V          V          V          V          V          V          V          V          V       \n",
      " worker2  V          V          V          V          *          V          V          *          V       \n",
      " worker3  V          V          V          V          V          V          V          V          V       \n",
      "\n",
      "  00:05\n",
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  V          V          V          V          V          V          V          V          V       \n",
      " worker2  V          V          V          V          *          V          V          V          V       \n",
      " worker3  V          V          V          V          V          V          V          V          V       \n",
      "\n",
      "  00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Context:0/0 Iteration 4: Trying parallel mapping...  \n",
      "          cluster_0  cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  cluster_7  prepost \n",
      " worker0  *          *          *          *          *          *          *          *          V       \n",
      " worker1  V          V          V          V          V          V          V          V          V       \n",
      " worker2  V          V          V          V          V          V          V          V          V       \n",
      " worker3  V          V          V          V          V          V          V          V          V       \n",
      "\n",
      "  00:07\n",
      "\n",
      "[info] Iterations: 4\n",
      "Reverts on cluster mapping: 0\n",
      "Reverts on inter-cluster connectivity: 0\n",
      "Reverts on pre-mapping validation: 1\n",
      "Reverts on split failed: 0\n",
      "[info] +-----------+---------------------+---------------------+--------------------+\n",
      "[info] | Cluster   | Control Utilization | Compute Utilization | Memory Utilization |\n",
      "[info] +-----------+---------------------+---------------------+--------------------+\n",
      "[info] | cluster_0 | 56.3%               | 82.8%               | 52.3%              |\n",
      "[info] | cluster_1 | 50%                 | 26.6%               | 25%                |\n",
      "[info] | cluster_2 | 37.5%               | 31.3%               | 30.5%              |\n",
      "[info] | cluster_3 | 25%                 | 17.2%               | 10.2%              |\n",
      "[info] | cluster_4 | 87.5%               | 98.4%               | 35.9%              |\n",
      "[info] | cluster_5 | 43.8%               | 54.7%               | 39.1%              |\n",
      "[info] | cluster_6 | 87.5%               | 100%                | 68%                |\n",
      "[info] | cluster_7 | 87.5%               | 90.6%               | 24.2%              |\n",
      "[info] +-----------+---------------------+---------------------+--------------------+\n",
      "[info] | Total     | 59.4%               | 62.7%               | 35.6%              |\n",
      "[info] +-----------+---------------------+---------------------+--------------------+\n",
      "[info] Successful Mapping (allocation time: 18s)\n",
      "[info] Compiling context_0...\n",
      "[info] Bandwidth of model inputs: 0.708984 Mbps, outputs: 0.00762939 Mbps (for a single frame)\n",
      "[info] Bandwidth of DDR buffers: 0.0 Mbps (for a single frame)\n",
      "[info] Bandwidth of inter context tensors: 0.0 Mbps (for a single frame)\n",
      "[info] Building HEF...\n",
      "[info] Successful Compilation (compilation time: 2s)\n"
     ]
    }
   ],
   "source": [
    "hef = runner.compile()\n",
    "\n",
    "file_name = f\"{onnx_model_name}.hef\"\n",
    "with open(file_name, \"wb\") as f:\n",
    "    f.write(hef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240685a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
